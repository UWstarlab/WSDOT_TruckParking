{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556408f3",
   "metadata": {},
   "source": [
    "## 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cc5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4febe8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401153c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff706cf9",
   "metadata": {},
   "source": [
    "## Load Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d35d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stamp</th>\n",
       "      <th>SegmentID</th>\n",
       "      <th>CabName</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Direction</th>\n",
       "      <th>mpdirection</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>35:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>45:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>50:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>55:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stamp  SegmentID     CabName  DayOfWeek Direction  mpdirection  \\\n",
       "0    00:00.0  114+04179  005es14630          6         d          NaN   \n",
       "1    05:00.0  114+04179  005es14630          6         d          NaN   \n",
       "2    10:00.0  114+04179  005es14630          6         d          NaN   \n",
       "3    15:00.0  114+04179  005es14630          6         d          NaN   \n",
       "4    20:00.0  114+04179  005es14630          6         d          NaN   \n",
       "..       ...        ...         ...        ...       ...          ...   \n",
       "995  35:00.0  114+04183  005es15348          6         d          NaN   \n",
       "996  40:00.0  114+04183  005es15348          6         d          NaN   \n",
       "997  45:00.0  114+04183  005es15348          6         d          NaN   \n",
       "998  50:00.0  114+04183  005es15348          6         d          NaN   \n",
       "999  55:00.0  114+04183  005es15348          6         d          NaN   \n",
       "\n",
       "     Occupancy  \n",
       "0           43  \n",
       "1           28  \n",
       "2           34  \n",
       "3           35  \n",
       "4           25  \n",
       "..         ...  \n",
       "995          3  \n",
       "996         27  \n",
       "997          9  \n",
       "998         31  \n",
       "999         36  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'sample_data.txt'\n",
    "\n",
    "# Read data from the text file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path, delimiter='\\t')  \n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f57019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>DayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occupancy  DayOfWeek\n",
       "0           43          6\n",
       "1           28          6\n",
       "2           34          6\n",
       "3           35          6\n",
       "4           25          6\n",
       "..         ...        ...\n",
       "786         28          6\n",
       "787         23          6\n",
       "788         23          6\n",
       "789          5          6\n",
       "790         27          6\n",
       "\n",
       "[339 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only segment 114+04179\n",
    "data179 = df[df['SegmentID']=='114+04179']\n",
    "#occ_matrix = data179[['Occupancy','DayOfWeek']]\n",
    "occ_matrix = data179[['Occupancy','DayOfWeek']]\n",
    "occ_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e2c03",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "efdd35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(occ_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of occ_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        occ_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    # KUKUU: speed_matrix.shape[0] = number of rows\n",
    "    time_len = occ_matrix.shape[0]\n",
    "    \n",
    "    # Normalization of Speed Matrix\n",
    "    max_occ = occ_matrix.max().max()\n",
    "    occ_matrix =  occ_matrix / max_occ\n",
    "    \n",
    "    # Sequence Generation\n",
    "    occ_sequences, occ_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        occ_sequences.append(occ_matrix.iloc[i:i+seq_len].values)\n",
    "        occ_labels.append(occ_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    occ_sequences, occ_labels = np.asarray(occ_sequences), np.asarray(occ_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = occ_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = occ_sequences[:train_index], occ_labels[:train_index]\n",
    "    valid_data, valid_label = occ_sequences[train_index:valid_index], occ_labels[train_index:valid_index]\n",
    "    test_data, test_label = occ_sequences[valid_index:], occ_labels[valid_index:]\n",
    "    \n",
    "    # Conversion to PyTorch Tensors\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    # Dataloader Creation\n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e7bd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, max_occ = PrepareDataset(occ_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53c47ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "# fea_size = feature size\n",
    "input_dim = fea_size\n",
    "hidden_dim = fea_size\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "550617fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate = 1e-5, num_epochs = 300, patience = 10, min_delta = 0.00001):\n",
    "    \n",
    "    inputs, labels = next(iter(train_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else: \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation \n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
    "            else: \n",
    "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
    "\n",
    "            outputs_val= model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                    epoch, \\\n",
    "                    np.around(avg_losses_epoch_train, decimals=8),\\\n",
    "                    np.around(avg_losses_epoch_valid, decimals=8),\\\n",
    "                    np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                    is_best_model) )\n",
    "        pre_time = cur_time\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "727c6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    \n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0a216f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c96676af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lstm \u001b[38;5;241m=\u001b[39m LSTM(input_dim, hidden_dim, output_dim, output_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m lstm, lstm_loss \u001b[38;5;241m=\u001b[39m \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m lstm_test \u001b[38;5;241m=\u001b[39m TestModel(lstm, test_dataloader, max_occ )\n",
      "Cell \u001b[1;32mIn[70], line 9\u001b[0m, in \u001b[0;36mTrainModel\u001b[1;34m(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, patience, min_delta)\u001b[0m\n\u001b[0;32m      6\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m fea_size\n\u001b[0;32m      7\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m fea_size\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss_MSE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     12\u001b[0m loss_L1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mL1Loss()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:918\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:918\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_occ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6043c0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.cuda.is_available() -> bool>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fde6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
