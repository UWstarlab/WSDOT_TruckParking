{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556408f3",
   "metadata": {},
   "source": [
    "## 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90cc5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4febe8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401153c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff706cf9",
   "metadata": {},
   "source": [
    "## Load Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d35d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>capacity</th>\n",
       "      <th>lowThreshold</th>\n",
       "      <th>open</th>\n",
       "      <th>reportedAvailable</th>\n",
       "      <th>timeStampStatic</th>\n",
       "      <th>trend</th>\n",
       "      <th>trustdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01T00:02:09Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01T00:04:09Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01T00:09:19Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01T00:15:59Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01T00:20:20Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101627</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01T23:51:05Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101628</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01T23:52:54Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101629</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01T23:55:52Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101630</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01T23:57:15Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101631</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01T23:59:31Z</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101632 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           siteId             timestamp  capacity  \\\n",
       "0       WI00039IS0011300SRSTARE11  2022-01-01T00:02:09Z        68   \n",
       "1       WI00039IS0011300SRSTARE11  2022-01-01T00:04:09Z        68   \n",
       "2       WI00039IS0011300SRSTARE11  2022-01-01T00:09:19Z        68   \n",
       "3       WI00039IS0011300SRSTARE11  2022-01-01T00:15:59Z        68   \n",
       "4       WI00039IS0011300SRSTARE11  2022-01-01T00:20:20Z        68   \n",
       "...                           ...                   ...       ...   \n",
       "101627  WI00039IS0011300SRSTARE11  2022-06-01T23:51:05Z        68   \n",
       "101628  WI00039IS0011300SRSTARE11  2022-06-01T23:52:54Z        68   \n",
       "101629  WI00039IS0011300SRSTARE11  2022-06-01T23:55:52Z        68   \n",
       "101630  WI00039IS0011300SRSTARE11  2022-06-01T23:57:15Z        68   \n",
       "101631  WI00039IS0011300SRSTARE11  2022-06-01T23:59:31Z        68   \n",
       "\n",
       "        lowThreshold  open reportedAvailable       timeStampStatic    trend  \\\n",
       "0                 13     1                54  2020-07-31T18:57:57Z  FILLING   \n",
       "1                 13     1                53  2020-07-31T18:57:57Z  FILLING   \n",
       "2                 13     1                54  2020-07-31T18:57:57Z  FILLING   \n",
       "3                 13     1                54  2020-07-31T18:57:57Z   STEADY   \n",
       "4                 13     1                54  2020-07-31T18:57:57Z   STEADY   \n",
       "...              ...   ...               ...                   ...      ...   \n",
       "101627            13     1                38  2020-07-31T18:57:57Z  FILLING   \n",
       "101628            13     1                39  2020-07-31T18:57:57Z   STEADY   \n",
       "101629            13     1                40  2020-07-31T18:57:57Z   STEADY   \n",
       "101630            13     1                39  2020-07-31T18:57:57Z   STEADY   \n",
       "101631            13     1                38  2020-07-31T18:57:57Z  FILLING   \n",
       "\n",
       "        trustdata  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "101627          1  \n",
       "101628          1  \n",
       "101629          1  \n",
       "101630          1  \n",
       "101631          1  \n",
       "\n",
       "[101632 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'TruckParkingQuery_20220101_20220601.csv'\n",
    "\n",
    "# Read data from the text file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)  \n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "704be05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.reportedAvailable == 'LOW', 'reportedAvailable'] = 0\n",
    "df['reportedAvailable'] = df['reportedAvailable'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4658bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['am_pm_indicator'] = (df['timestamp'].dt.hour // 12).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bed5762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>capacity</th>\n",
       "      <th>lowThreshold</th>\n",
       "      <th>open</th>\n",
       "      <th>reportedAvailable</th>\n",
       "      <th>timeStampStatic</th>\n",
       "      <th>trend</th>\n",
       "      <th>trustdata</th>\n",
       "      <th>am_pm_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01 00:02:09+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01 00:04:09+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01 00:09:19+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01 00:15:59+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-01-01 00:20:20+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101627</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01 23:51:05+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101628</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01 23:52:54+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101629</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01 23:55:52+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101630</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01 23:57:15+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>STEADY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101631</th>\n",
       "      <td>WI00039IS0011300SRSTARE11</td>\n",
       "      <td>2022-06-01 23:59:31+00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-07-31T18:57:57Z</td>\n",
       "      <td>FILLING</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101632 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           siteId                 timestamp  capacity  \\\n",
       "0       WI00039IS0011300SRSTARE11 2022-01-01 00:02:09+00:00        68   \n",
       "1       WI00039IS0011300SRSTARE11 2022-01-01 00:04:09+00:00        68   \n",
       "2       WI00039IS0011300SRSTARE11 2022-01-01 00:09:19+00:00        68   \n",
       "3       WI00039IS0011300SRSTARE11 2022-01-01 00:15:59+00:00        68   \n",
       "4       WI00039IS0011300SRSTARE11 2022-01-01 00:20:20+00:00        68   \n",
       "...                           ...                       ...       ...   \n",
       "101627  WI00039IS0011300SRSTARE11 2022-06-01 23:51:05+00:00        68   \n",
       "101628  WI00039IS0011300SRSTARE11 2022-06-01 23:52:54+00:00        68   \n",
       "101629  WI00039IS0011300SRSTARE11 2022-06-01 23:55:52+00:00        68   \n",
       "101630  WI00039IS0011300SRSTARE11 2022-06-01 23:57:15+00:00        68   \n",
       "101631  WI00039IS0011300SRSTARE11 2022-06-01 23:59:31+00:00        68   \n",
       "\n",
       "        lowThreshold  open  reportedAvailable       timeStampStatic    trend  \\\n",
       "0                 13     1                 54  2020-07-31T18:57:57Z  FILLING   \n",
       "1                 13     1                 53  2020-07-31T18:57:57Z  FILLING   \n",
       "2                 13     1                 54  2020-07-31T18:57:57Z  FILLING   \n",
       "3                 13     1                 54  2020-07-31T18:57:57Z   STEADY   \n",
       "4                 13     1                 54  2020-07-31T18:57:57Z   STEADY   \n",
       "...              ...   ...                ...                   ...      ...   \n",
       "101627            13     1                 38  2020-07-31T18:57:57Z  FILLING   \n",
       "101628            13     1                 39  2020-07-31T18:57:57Z   STEADY   \n",
       "101629            13     1                 40  2020-07-31T18:57:57Z   STEADY   \n",
       "101630            13     1                 39  2020-07-31T18:57:57Z   STEADY   \n",
       "101631            13     1                 38  2020-07-31T18:57:57Z  FILLING   \n",
       "\n",
       "        trustdata  am_pm_indicator  \n",
       "0               1                0  \n",
       "1               1                0  \n",
       "2               1                0  \n",
       "3               1                0  \n",
       "4               1                0  \n",
       "...           ...              ...  \n",
       "101627          1                1  \n",
       "101628          1                1  \n",
       "101629          1                1  \n",
       "101630          1                1  \n",
       "101631          1                1  \n",
       "\n",
       "[101632 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f57019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportedAvailable</th>\n",
       "      <th>am_pm_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101627</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101628</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101629</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101630</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101631</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101632 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reportedAvailable  am_pm_indicator\n",
       "0                      54                0\n",
       "1                      53                0\n",
       "2                      54                0\n",
       "3                      54                0\n",
       "4                      54                0\n",
       "...                   ...              ...\n",
       "101627                 38                1\n",
       "101628                 39                1\n",
       "101629                 40                1\n",
       "101630                 39                1\n",
       "101631                 38                1\n",
       "\n",
       "[101632 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only segment 114+04179\n",
    "occ_matrix = df[['reportedAvailable','am_pm_indicator']]\n",
    "occ_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e2c03",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efdd35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(occ_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of occ_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        occ_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    # number of rows\n",
    "    time_len = occ_matrix.shape[0]\n",
    "    \n",
    "    # Normalization \n",
    "    max_occ = occ_matrix.max().max()\n",
    "    occ_matrix =  occ_matrix / max_occ\n",
    "    \n",
    "    # Sequence Generation\n",
    "    occ_sequences, occ_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        occ_sequences.append(occ_matrix.iloc[i:i+seq_len].values)\n",
    "        occ_labels.append(occ_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    occ_sequences, occ_labels = np.asarray(occ_sequences), np.asarray(occ_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = occ_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = occ_sequences[:train_index], occ_labels[:train_index]\n",
    "    valid_data, valid_label = occ_sequences[train_index:valid_index], occ_labels[train_index:valid_index]\n",
    "    test_data, test_label = occ_sequences[valid_index:], occ_labels[valid_index:]\n",
    "    \n",
    "    # Conversion to PyTorch Tensors\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    # Dataloader Creation\n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e7bd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, max_occ = PrepareDataset(occ_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53c47ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "# fea_size = feature size\n",
    "input_dim = fea_size\n",
    "hidden_dim = fea_size\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "262a31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate=1e-5, num_epochs=300, patience=10, min_delta=0.00001):\n",
    "    \"\"\"Train a PyTorch model using training and validation data\n",
    "    model = model name\n",
    "    train_dataloader = dataset for training\n",
    "    valid_dataloader = dataset for validation\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Data Handling\n",
    "    # Extracts the dimensions of the input data from the first batch in the training dataset\n",
    "    [batch_size, step_size, fea_size] = next(iter(train_dataloader))[0].size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    # 2) Device Selection\n",
    "    # Chooses the device (GPU if available, otherwise CPU) for computation\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Moves the model to the chosen device\n",
    "    model.to(device)\n",
    "    \n",
    "    # 3) Loss Functions and Optimizer\n",
    "    # Defines the Mean Squared Error loss\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "    \n",
    "    # Initializes the RMSprop optimizer with specified learning rate\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Variables for logging losses and early stopping\n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    # Time tracking variables\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    \n",
    "    # 4) Training Loops\n",
    "    # Performs forward pass, computes the loss, performs backward pass, and updates the model parameters.\n",
    "    # Iterates over epochs and batches in the training data\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        # Iterator for validation data\n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "        \n",
    "        # Loop over training data\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Skip incomplete batches\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "            \n",
    "            # Move data to the chosen device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Set the gradients to zero before starting to do backpropagation\n",
    "            # Zero the gradients, forward pass, backward pass, optimize\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.item())\n",
    "            losses_epoch_train.append(loss_train.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # 5) Validation\n",
    "            # performed after each training epoch\n",
    "            # Uses a separate validation dataset (valid_dataloader)\n",
    "            # Monitors and logs training and validation losses\n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "            outputs_val = model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.item())\n",
    "            losses_epoch_valid.append(loss_valid.item())\n",
    "            \n",
    "            # Output\n",
    "            trained_number += 1\n",
    "        \n",
    "        # Calculate average losses for the epoch\n",
    "        avg_losses_epoch_train = np.mean(losses_epoch_train)\n",
    "        avg_losses_epoch_valid = np.mean(losses_epoch_valid)\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # 6) Early Stopping\n",
    "        # Implements early stopping based on the validation loss\n",
    "        # Terminates training if the validation loss doesn't improve for a certain number of consecutive epochs.\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format(\n",
    "            epoch,\n",
    "            np.around(avg_losses_epoch_train, decimals=8),\n",
    "            np.around(avg_losses_epoch_valid, decimals=8),\n",
    "            np.around([cur_time - pre_time], decimals=2),\n",
    "            is_best_model))\n",
    "        pre_time = cur_time\n",
    "    \n",
    "    # Return the best model and the collected losses\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "727c6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    \n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "270619c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \"\"\"Evaluating a PyTorch model on a test dataset\"\"\"\n",
    "    # 1) Data Handling\n",
    "    # Attempts to extract the first batch of test data, handling the case where the test dataset is empty\n",
    "    try:\n",
    "        inputs, labels = next(iter(test_dataloader))\n",
    "    except StopIteration:\n",
    "        return ['lol']  \n",
    "    \n",
    "    # Extract dimensions of input data from the first batch in the test dataset\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    \n",
    "    # Record the current time for time tracking\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # 2) Device Selection\n",
    "    # Check if GPU is available\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    # 3) Loss Functions\n",
    "    # Define loss functions (Mean Squared Error loss + the L1 Loss)\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "    \n",
    "    # 4) Testing Loop\n",
    "    # Performs a forward pass through the model and calculates MSE and L1 losses\n",
    "    # Initialize variables for tracking testing progress\n",
    "    tested_batch = 0\n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    # Loop over batches in the test dataset\n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Skip incomplete batches\n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "        \n",
    "        # Move data to GPU if available\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss values\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "        \n",
    "        # Append loss values to lists for later analysis\n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "        \n",
    "        tested_batch += 1\n",
    "        \n",
    "        # Print testing progress every 1000 batches\n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    \n",
    "    # Convert lists of losses to NumPy arrays for further analysis\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    \n",
    "    # Calculate mean and standard deviation of L1 losses\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    \n",
    "    # Return a list containing losses and summary statistics\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0a216f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        A simple Long Short-Term Memory (LSTM) module\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Initialize LSTM parameters\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # Decide whether to output only the last step's hidden state\n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \"\"\"LSTM cell operation for a single time step\"\"\"\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            \"\"\"Output only the hidden state of the last time step\"\"\"\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        \"\"\" Initialize hidden and cell states for the first time step\"\"\"\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c96676af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.29980175, valid_loss: 0.28774905, time: [40.98], best model: 1\n",
      "Epoch: 1, train_loss: 0.28540788, valid_loss: 0.27362828, time: [41.11], best model: 1\n",
      "Epoch: 2, train_loss: 0.27240828, valid_loss: 0.26110488, time: [39.72], best model: 1\n",
      "Epoch: 3, train_loss: 0.26055755, valid_loss: 0.24962993, time: [39.68], best model: 1\n",
      "Epoch: 4, train_loss: 0.24978973, valid_loss: 0.2392128, time: [38.9], best model: 1\n",
      "Epoch: 5, train_loss: 0.24001846, valid_loss: 0.22995367, time: [38.79], best model: 1\n",
      "Epoch: 6, train_loss: 0.23118523, valid_loss: 0.22136126, time: [38.86], best model: 1\n",
      "Epoch: 7, train_loss: 0.22320441, valid_loss: 0.21355233, time: [39.05], best model: 1\n",
      "Epoch: 8, train_loss: 0.21562205, valid_loss: 0.20603535, time: [38.86], best model: 1\n",
      "Epoch: 9, train_loss: 0.20748705, valid_loss: 0.19846474, time: [38.47], best model: 1\n",
      "Epoch: 10, train_loss: 0.1986328, valid_loss: 0.18973069, time: [38.74], best model: 1\n",
      "Epoch: 11, train_loss: 0.18904853, valid_loss: 0.18064398, time: [38.68], best model: 1\n",
      "Epoch: 12, train_loss: 0.17871689, valid_loss: 0.17075188, time: [38.91], best model: 1\n",
      "Epoch: 13, train_loss: 0.16769199, valid_loss: 0.16007622, time: [38.42], best model: 1\n",
      "Epoch: 14, train_loss: 0.15604622, valid_loss: 0.14921028, time: [38.17], best model: 1\n",
      "Epoch: 15, train_loss: 0.14386761, valid_loss: 0.13721956, time: [38.28], best model: 1\n",
      "Epoch: 16, train_loss: 0.13132713, valid_loss: 0.1252875, time: [38.07], best model: 1\n",
      "Epoch: 17, train_loss: 0.11854499, valid_loss: 0.11303398, time: [37.58], best model: 1\n",
      "Epoch: 18, train_loss: 0.10581155, valid_loss: 0.10075405, time: [37.85], best model: 1\n",
      "Epoch: 19, train_loss: 0.09333716, valid_loss: 0.08879604, time: [39.35], best model: 1\n",
      "Epoch: 20, train_loss: 0.08136335, valid_loss: 0.07709195, time: [44.11], best model: 1\n",
      "Epoch: 21, train_loss: 0.07013153, valid_loss: 0.06633334, time: [44.32], best model: 1\n",
      "Epoch: 22, train_loss: 0.05981955, valid_loss: 0.05639997, time: [44.22], best model: 1\n",
      "Epoch: 23, train_loss: 0.05056588, valid_loss: 0.04744809, time: [44.41], best model: 1\n",
      "Epoch: 24, train_loss: 0.04248099, valid_loss: 0.03958983, time: [44.43], best model: 1\n",
      "Epoch: 25, train_loss: 0.03557773, valid_loss: 0.03295804, time: [44.42], best model: 1\n",
      "Epoch: 26, train_loss: 0.02984462, valid_loss: 0.02742741, time: [44.72], best model: 1\n",
      "Epoch: 27, train_loss: 0.02523271, valid_loss: 0.02298676, time: [1943.89], best model: 1\n",
      "Epoch: 28, train_loss: 0.02164254, valid_loss: 0.0195576, time: [39.93], best model: 1\n",
      "Epoch: 29, train_loss: 0.01891631, valid_loss: 0.01702049, time: [44.], best model: 1\n",
      "Epoch: 30, train_loss: 0.01671617, valid_loss: 0.01497113, time: [44.07], best model: 1\n",
      "Epoch: 31, train_loss: 0.0147769, valid_loss: 0.01316497, time: [44.36], best model: 1\n",
      "Epoch: 32, train_loss: 0.01307097, valid_loss: 0.01157789, time: [43.91], best model: 1\n",
      "Epoch: 33, train_loss: 0.01157768, valid_loss: 0.01019007, time: [43.8], best model: 1\n",
      "Epoch: 34, train_loss: 0.01028269, valid_loss: 0.0089951, time: [42.41], best model: 1\n",
      "Epoch: 35, train_loss: 0.00913891, valid_loss: 0.00797319, time: [41.32], best model: 1\n",
      "Epoch: 36, train_loss: 0.00812134, valid_loss: 0.0070563, time: [40.15], best model: 1\n",
      "Epoch: 37, train_loss: 0.00721727, valid_loss: 0.00626659, time: [39.56], best model: 1\n",
      "Epoch: 38, train_loss: 0.00641254, valid_loss: 0.00552628, time: [40.47], best model: 1\n",
      "Epoch: 39, train_loss: 0.00569742, valid_loss: 0.00489647, time: [39.3], best model: 1\n",
      "Epoch: 40, train_loss: 0.00506431, valid_loss: 0.00434149, time: [38.53], best model: 1\n",
      "Epoch: 41, train_loss: 0.00450163, valid_loss: 0.00385282, time: [38.37], best model: 1\n",
      "Epoch: 42, train_loss: 0.00400738, valid_loss: 0.00343776, time: [39.45], best model: 1\n",
      "Epoch: 43, train_loss: 0.00357114, valid_loss: 0.00305884, time: [41.05], best model: 1\n",
      "Epoch: 44, train_loss: 0.00318712, valid_loss: 0.00273576, time: [42.18], best model: 1\n",
      "Epoch: 45, train_loss: 0.00285407, valid_loss: 0.00245786, time: [41.91], best model: 1\n",
      "Epoch: 46, train_loss: 0.00256389, valid_loss: 0.00220398, time: [39.4], best model: 1\n",
      "Epoch: 47, train_loss: 0.00231272, valid_loss: 0.00199713, time: [42.33], best model: 1\n",
      "Epoch: 48, train_loss: 0.00209476, valid_loss: 0.00181528, time: [41.7], best model: 1\n",
      "Epoch: 49, train_loss: 0.00190757, valid_loss: 0.00166343, time: [41.16], best model: 1\n",
      "Epoch: 50, train_loss: 0.0017468, valid_loss: 0.00153204, time: [38.75], best model: 1\n",
      "Epoch: 51, train_loss: 0.00160861, valid_loss: 0.00141903, time: [39.46], best model: 1\n",
      "Epoch: 52, train_loss: 0.00148991, valid_loss: 0.00132357, time: [40.51], best model: 1\n",
      "Epoch: 53, train_loss: 0.00138867, valid_loss: 0.00124344, time: [40.44], best model: 1\n",
      "Epoch: 54, train_loss: 0.00130207, valid_loss: 0.00117296, time: [38.78], best model: 1\n",
      "Epoch: 55, train_loss: 0.00122826, valid_loss: 0.0011145, time: [39.92], best model: 1\n",
      "Epoch: 56, train_loss: 0.00116429, valid_loss: 0.00106238, time: [39.92], best model: 1\n",
      "Epoch: 57, train_loss: 0.00110922, valid_loss: 0.00102041, time: [41.16], best model: 1\n",
      "Epoch: 58, train_loss: 0.00106185, valid_loss: 0.00098118, time: [42.16], best model: 1\n",
      "Epoch: 59, train_loss: 0.0010211, valid_loss: 0.00094894, time: [41.05], best model: 1\n",
      "Epoch: 60, train_loss: 0.00098566, valid_loss: 0.00091794, time: [41.7], best model: 1\n",
      "Epoch: 61, train_loss: 0.00095504, valid_loss: 0.00089631, time: [40.95], best model: 1\n",
      "Epoch: 62, train_loss: 0.00092777, valid_loss: 0.00087514, time: [42.22], best model: 1\n",
      "Epoch: 63, train_loss: 0.00090377, valid_loss: 0.00085656, time: [42.08], best model: 1\n",
      "Epoch: 64, train_loss: 0.00088222, valid_loss: 0.00083913, time: [38.41], best model: 1\n",
      "Epoch: 65, train_loss: 0.00086333, valid_loss: 0.00082529, time: [38.53], best model: 1\n",
      "Epoch: 66, train_loss: 0.00084609, valid_loss: 0.00080989, time: [42.11], best model: 1\n",
      "Epoch: 67, train_loss: 0.00083054, valid_loss: 0.00079809, time: [42.41], best model: 1\n",
      "Epoch: 68, train_loss: 0.00081643, valid_loss: 0.00078637, time: [41.82], best model: 1\n",
      "Epoch: 69, train_loss: 0.00080319, valid_loss: 0.00077538, time: [46.58], best model: 1\n",
      "Epoch: 70, train_loss: 0.00079125, valid_loss: 0.000769, time: [39.36], best model: 0\n",
      "Epoch: 71, train_loss: 0.00078002, valid_loss: 0.000758, time: [41.29], best model: 1\n",
      "Epoch: 72, train_loss: 0.00077018, valid_loss: 0.00074996, time: [39.23], best model: 0\n",
      "Epoch: 73, train_loss: 0.00076062, valid_loss: 0.00074236, time: [39.23], best model: 1\n",
      "Epoch: 74, train_loss: 0.00075197, valid_loss: 0.00073297, time: [41.66], best model: 0\n",
      "Epoch: 75, train_loss: 0.00074365, valid_loss: 0.00072873, time: [40.62], best model: 1\n",
      "Epoch: 76, train_loss: 0.00073567, valid_loss: 0.00071964, time: [40.99], best model: 0\n",
      "Epoch: 77, train_loss: 0.00072824, valid_loss: 0.00071387, time: [41.64], best model: 1\n",
      "Epoch: 78, train_loss: 0.00072106, valid_loss: 0.00070832, time: [42.01], best model: 0\n",
      "Epoch: 79, train_loss: 0.00071413, valid_loss: 0.00070265, time: [42.15], best model: 1\n",
      "Epoch: 80, train_loss: 0.0007076, valid_loss: 0.00069691, time: [40.23], best model: 0\n",
      "Epoch: 81, train_loss: 0.00070129, valid_loss: 0.0006895, time: [37.87], best model: 1\n",
      "Epoch: 82, train_loss: 0.00069492, valid_loss: 0.00068562, time: [36.46], best model: 0\n",
      "Epoch: 83, train_loss: 0.00068917, valid_loss: 0.00068094, time: [36.41], best model: 0\n",
      "Epoch: 84, train_loss: 0.00068336, valid_loss: 0.00067315, time: [36.48], best model: 1\n",
      "Epoch: 85, train_loss: 0.00067773, valid_loss: 0.00066829, time: [35.77], best model: 0\n",
      "Epoch: 86, train_loss: 0.00067222, valid_loss: 0.00066397, time: [35.93], best model: 0\n",
      "Epoch: 87, train_loss: 0.00066709, valid_loss: 0.00066129, time: [35.84], best model: 1\n",
      "Epoch: 88, train_loss: 0.00066176, valid_loss: 0.00065754, time: [35.92], best model: 0\n",
      "Epoch: 89, train_loss: 0.00065705, valid_loss: 0.00065315, time: [35.74], best model: 0\n",
      "Epoch: 90, train_loss: 0.00065225, valid_loss: 0.00064667, time: [35.67], best model: 1\n",
      "Epoch: 91, train_loss: 0.00064754, valid_loss: 0.00064082, time: [35.99], best model: 0\n",
      "Epoch: 92, train_loss: 0.00064284, valid_loss: 0.00063644, time: [36.17], best model: 1\n",
      "Epoch: 93, train_loss: 0.00063812, valid_loss: 0.00063169, time: [36.12], best model: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, train_loss: 0.00063369, valid_loss: 0.00062775, time: [36.15], best model: 0\n",
      "Epoch: 95, train_loss: 0.00062924, valid_loss: 0.00062798, time: [36.05], best model: 0\n",
      "Epoch: 96, train_loss: 0.00062489, valid_loss: 0.00061988, time: [36.23], best model: 1\n",
      "Epoch: 97, train_loss: 0.00062072, valid_loss: 0.00061631, time: [36.38], best model: 0\n",
      "Epoch: 98, train_loss: 0.00061646, valid_loss: 0.00061429, time: [36.15], best model: 0\n",
      "Epoch: 99, train_loss: 0.00061232, valid_loss: 0.00060967, time: [36.43], best model: 1\n",
      "Tested: L1_mean: 1.0365047082304955, L1_std : 0.1263682753778994\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 100)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_occ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "337759f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (fl): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (il): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (ol): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (Cl): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17b05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
