{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556408f3",
   "metadata": {},
   "source": [
    "## 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cc5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4febe8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401153c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff706cf9",
   "metadata": {},
   "source": [
    "## Load Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d35d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stamp</th>\n",
       "      <th>SegmentID</th>\n",
       "      <th>CabName</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Direction</th>\n",
       "      <th>mpdirection</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20:00.0</td>\n",
       "      <td>114+04179</td>\n",
       "      <td>005es14630</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>35:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>45:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>50:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>55:00.0</td>\n",
       "      <td>114+04183</td>\n",
       "      <td>005es15348</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stamp  SegmentID     CabName  DayOfWeek Direction  mpdirection  \\\n",
       "0    00:00.0  114+04179  005es14630          6         d          NaN   \n",
       "1    05:00.0  114+04179  005es14630          6         d          NaN   \n",
       "2    10:00.0  114+04179  005es14630          6         d          NaN   \n",
       "3    15:00.0  114+04179  005es14630          6         d          NaN   \n",
       "4    20:00.0  114+04179  005es14630          6         d          NaN   \n",
       "..       ...        ...         ...        ...       ...          ...   \n",
       "995  35:00.0  114+04183  005es15348          6         d          NaN   \n",
       "996  40:00.0  114+04183  005es15348          6         d          NaN   \n",
       "997  45:00.0  114+04183  005es15348          6         d          NaN   \n",
       "998  50:00.0  114+04183  005es15348          6         d          NaN   \n",
       "999  55:00.0  114+04183  005es15348          6         d          NaN   \n",
       "\n",
       "     Occupancy  \n",
       "0           43  \n",
       "1           28  \n",
       "2           34  \n",
       "3           35  \n",
       "4           25  \n",
       "..         ...  \n",
       "995          3  \n",
       "996         27  \n",
       "997          9  \n",
       "998         31  \n",
       "999         36  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'sample_data.txt'\n",
    "\n",
    "# Read data from the text file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path, delimiter='\\t')  \n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f57019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>DayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occupancy  DayOfWeek\n",
       "0           43          6\n",
       "1           28          6\n",
       "2           34          6\n",
       "3           35          6\n",
       "4           25          6\n",
       "..         ...        ...\n",
       "786         28          6\n",
       "787         23          6\n",
       "788         23          6\n",
       "789          5          6\n",
       "790         27          6\n",
       "\n",
       "[339 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only segment 114+04179\n",
    "data179 = df[df['SegmentID']=='114+04179']\n",
    "occ_matrix = data179[['Occupancy','DayOfWeek']]\n",
    "occ_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e2c03",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdd35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(occ_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of occ_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        occ_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    # number of rows\n",
    "    time_len = occ_matrix.shape[0]\n",
    "    \n",
    "    # Normalization \n",
    "    max_occ = occ_matrix.max().max()\n",
    "    occ_matrix =  occ_matrix / max_occ\n",
    "    \n",
    "    # Sequence Generation\n",
    "    occ_sequences, occ_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        occ_sequences.append(occ_matrix.iloc[i:i+seq_len].values)\n",
    "        occ_labels.append(occ_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    occ_sequences, occ_labels = np.asarray(occ_sequences), np.asarray(occ_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = occ_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = occ_sequences[:train_index], occ_labels[:train_index]\n",
    "    valid_data, valid_label = occ_sequences[train_index:valid_index], occ_labels[train_index:valid_index]\n",
    "    test_data, test_label = occ_sequences[valid_index:], occ_labels[valid_index:]\n",
    "    \n",
    "    # Conversion to PyTorch Tensors\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    # Dataloader Creation\n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7bd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, max_occ = PrepareDataset(occ_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c47ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "# fea_size = feature size\n",
    "input_dim = fea_size\n",
    "hidden_dim = fea_size\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550617fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate = 1e-5, num_epochs = 300, patience = 10, min_delta = 0.00001):\n",
    "    \n",
    "    inputs, labels = next(iter(train_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else: \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation \n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
    "            else: \n",
    "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
    "\n",
    "            outputs_val= model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                    epoch, \\\n",
    "                    np.around(avg_losses_epoch_train, decimals=8),\\\n",
    "                    np.around(avg_losses_epoch_valid, decimals=8),\\\n",
    "                    np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                    is_best_model) )\n",
    "        pre_time = cur_time\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "262a31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate=1e-5, num_epochs=300, patience=10, min_delta=0.00001):\n",
    "    \"\"\"Train a PyTorch model using training and validation data\n",
    "    model = model name\n",
    "    train_dataloader = dataset for training\n",
    "    valid_dataloader = dataset for validation\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Data Handling\n",
    "    # Extracts the dimensions of the input data from the first batch in the training dataset\n",
    "    [batch_size, step_size, fea_size] = next(iter(train_dataloader))[0].size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    # 2) Device Selection\n",
    "    # Chooses the device (GPU if available, otherwise CPU) for computation\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Moves the model to the chosen device\n",
    "    model.to(device)\n",
    "    \n",
    "    # 3) Loss Functions and Optimizer\n",
    "    # Defines the Mean Squared Error loss\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "    \n",
    "    # Initializes the RMSprop optimizer with specified learning rate\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Variables for logging losses and early stopping\n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    # Time tracking variables\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    \n",
    "    # 4) Training Loops\n",
    "    # Performs forward pass, computes the loss, performs backward pass, and updates the model parameters.\n",
    "    # Iterates over epochs and batches in the training data\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        # Iterator for validation data\n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "        \n",
    "        # Loop over training data\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Skip incomplete batches\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "            \n",
    "            # Move data to the chosen device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Set the gradients to zero before starting to do backpropagation\n",
    "            # Zero the gradients, forward pass, backward pass, optimize\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.item())\n",
    "            losses_epoch_train.append(loss_train.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # 5) Validation\n",
    "            # performed after each training epoch\n",
    "            # Uses a separate validation dataset (valid_dataloader)\n",
    "            # Monitors and logs training and validation losses\n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "            outputs_val = model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.item())\n",
    "            losses_epoch_valid.append(loss_valid.item())\n",
    "            \n",
    "            # Output\n",
    "            trained_number += 1\n",
    "        \n",
    "        # Calculate average losses for the epoch\n",
    "        avg_losses_epoch_train = np.mean(losses_epoch_train)\n",
    "        avg_losses_epoch_valid = np.mean(losses_epoch_valid)\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # 6) Early Stopping\n",
    "        # Implements early stopping based on the validation loss\n",
    "        # Terminates training if the validation loss doesn't improve for a certain number of consecutive epochs.\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format(\n",
    "            epoch,\n",
    "            np.around(avg_losses_epoch_train, decimals=8),\n",
    "            np.around(avg_losses_epoch_valid, decimals=8),\n",
    "            np.around([cur_time - pre_time], decimals=2),\n",
    "            is_best_model))\n",
    "        pre_time = cur_time\n",
    "    \n",
    "    # Return the best model and the collected losses\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "727c6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    \n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "270619c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \"\"\"Evaluating a PyTorch model on a test dataset\"\"\"\n",
    "    # 1) Data Handling\n",
    "    # Attempts to extract the first batch of test data, handling the case where the test dataset is empty\n",
    "    try:\n",
    "        inputs, labels = next(iter(test_dataloader))\n",
    "    except StopIteration:\n",
    "        return ['lol']  \n",
    "    \n",
    "    # Extract dimensions of input data from the first batch in the test dataset\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    \n",
    "    # Record the current time for time tracking\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # 2) Device Selection\n",
    "    # Check if GPU is available\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    # 3) Loss Functions\n",
    "    # Define loss functions (Mean Squared Error loss + the L1 Loss)\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "    \n",
    "    # 4) Testing Loop\n",
    "    # Performs a forward pass through the model and calculates MSE and L1 losses\n",
    "    # Initialize variables for tracking testing progress\n",
    "    tested_batch = 0\n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    # Loop over batches in the test dataset\n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Skip incomplete batches\n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "        \n",
    "        # Move data to GPU if available\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss values\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "        \n",
    "        # Append loss values to lists for later analysis\n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "        \n",
    "        tested_batch += 1\n",
    "        \n",
    "        # Print testing progress every 1000 batches\n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    \n",
    "    # Convert lists of losses to NumPy arrays for further analysis\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    \n",
    "    # Calculate mean and standard deviation of L1 losses\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    \n",
    "    # Return a list containing losses and summary statistics\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a216f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        A simple Long Short-Term Memory (LSTM) module\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Initialize LSTM parameters\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # Decide whether to output only the last step's hidden state\n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \"\"\"LSTM cell operation for a single time step\"\"\"\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            \"\"\"Output only the hidden state of the last time step\"\"\"\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        \"\"\" Initialize hidden and cell states for the first time step\"\"\"\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c96676af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.17317875, valid_loss: 0.15625469, time: [0.12], best model: 1\n",
      "Epoch: 1, train_loss: 0.17799926, valid_loss: 0.15819702, time: [0.11], best model: 0\n",
      "Epoch: 2, train_loss: 0.17356007, valid_loss: 0.1581965, time: [0.11], best model: 0\n",
      "Epoch: 3, train_loss: 0.17575182, valid_loss: 0.15742014, time: [0.12], best model: 0\n",
      "Epoch: 4, train_loss: 0.17405716, valid_loss: 0.16423849, time: [0.11], best model: 0\n",
      "Epoch: 5, train_loss: 0.17064195, valid_loss: 0.15746343, time: [0.11], best model: 0\n",
      "Epoch: 6, train_loss: 0.17979847, valid_loss: 0.16033303, time: [0.11], best model: 0\n",
      "Epoch: 7, train_loss: 0.17822318, valid_loss: 0.15662036, time: [0.11], best model: 0\n",
      "Epoch: 8, train_loss: 0.17292292, valid_loss: 0.1520056, time: [0.1], best model: 1\n",
      "Epoch: 9, train_loss: 0.175442, valid_loss: 0.15672659, time: [0.11], best model: 0\n",
      "Epoch: 10, train_loss: 0.18058374, valid_loss: 0.14904018, time: [0.1], best model: 1\n",
      "Epoch: 11, train_loss: 0.17147442, valid_loss: 0.15668346, time: [0.11], best model: 0\n",
      "Epoch: 12, train_loss: 0.17530016, valid_loss: 0.14925187, time: [0.11], best model: 0\n",
      "Epoch: 13, train_loss: 0.1760153, valid_loss: 0.14940672, time: [0.1], best model: 0\n",
      "Epoch: 14, train_loss: 0.17654272, valid_loss: 0.15308925, time: [0.11], best model: 0\n",
      "Epoch: 15, train_loss: 0.17393191, valid_loss: 0.14481972, time: [0.1], best model: 1\n",
      "Epoch: 16, train_loss: 0.17882132, valid_loss: 0.15379286, time: [0.11], best model: 0\n",
      "Epoch: 17, train_loss: 0.1801076, valid_loss: 0.15290955, time: [0.11], best model: 0\n",
      "Epoch: 18, train_loss: 0.17767688, valid_loss: 0.14949481, time: [0.11], best model: 0\n",
      "Epoch: 19, train_loss: 0.17635941, valid_loss: 0.1578647, time: [0.1], best model: 0\n",
      "Epoch: 20, train_loss: 0.17261883, valid_loss: 0.15604324, time: [0.11], best model: 0\n",
      "Epoch: 21, train_loss: 0.17868761, valid_loss: 0.14133317, time: [0.1], best model: 1\n",
      "Epoch: 22, train_loss: 0.17550195, valid_loss: 0.15774638, time: [0.11], best model: 0\n",
      "Epoch: 23, train_loss: 0.17427369, valid_loss: 0.14836137, time: [0.11], best model: 0\n",
      "Epoch: 24, train_loss: 0.17972914, valid_loss: 0.15505093, time: [0.1], best model: 0\n",
      "Epoch: 25, train_loss: 0.17313991, valid_loss: 0.15384897, time: [0.11], best model: 0\n",
      "Epoch: 26, train_loss: 0.17329342, valid_loss: 0.15184135, time: [0.1], best model: 0\n",
      "Epoch: 27, train_loss: 0.17502127, valid_loss: 0.15613723, time: [0.11], best model: 0\n",
      "Epoch: 28, train_loss: 0.17377675, valid_loss: 0.15488287, time: [0.1], best model: 0\n",
      "Epoch: 29, train_loss: 0.17521093, valid_loss: 0.15202, time: [0.1], best model: 0\n",
      "Epoch: 30, train_loss: 0.17305973, valid_loss: 0.15817947, time: [0.11], best model: 0\n",
      "Early Stopped at Epoch: 31\n",
      "Tested: L1_mean: nan, L1_std : nan\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 100)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_occ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2cd20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified 2\n",
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    #inputs, labels = next(iter(test_dataloader))\n",
    "    #[batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    #batch_size, step_size, fea_size = test_dataloader.dataset[0][0].size()\n",
    "    batch_size, fea_size = test_dataloader.dataset[0][0].size()\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().item())\n",
    "        losses_l1.append(loss_l1.cpu().item())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.item()], decimals=8), \\\n",
    "                  np.around([loss_mse.item()], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    \n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "337759f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([], dtype=float64), array([], dtype=float64), nan, nan]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17b05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
